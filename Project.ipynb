{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle and pedestrian stops in Vermont"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data consists of vehicle and pedestrian stops from law enforcement departments in Vermont. Using this dataset we will try to predict the outcome (whether it results in an arrest) of the traffic stop using its features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Headers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Enable inline mode for matplotlib so that Jupyter displays graphs\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows vs Number of columns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(283285, 23)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the data\n",
    "data = pd.read_csv('vermont.csv', header='infer')\n",
    "print('Number of rows vs Number of columns')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is missing values in many columns. We can see how many values in each column are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                            0\n",
       "state                         0\n",
       "stop_date                     0\n",
       "stop_time                     0\n",
       "location_raw                694\n",
       "county_name                 705\n",
       "county_fips                 705\n",
       "fine_grained_location       347\n",
       "police_department             0\n",
       "driver_gender              1712\n",
       "driver_age_raw             1171\n",
       "driver_age                 1286\n",
       "driver_race_raw            3984\n",
       "driver_race                4817\n",
       "violation_raw              2178\n",
       "violation                  2178\n",
       "search_conducted              0\n",
       "search_type_raw            2240\n",
       "search_type              279866\n",
       "contraband_found             34\n",
       "stop_outcome               2325\n",
       "is_arrested                   0\n",
       "officer_id                   12\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#All missing values for each column\n",
    "pd.isnull(data).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of the dataset is big and some features are needed to build an accurate model, therefore we will delete all records with missing categorical data.\n",
    "For some numerical data, we will do imputation, using the mean of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean= 38.805525581327295\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                            0\n",
       "state                         0\n",
       "stop_date                     0\n",
       "stop_time                     0\n",
       "location_raw                  0\n",
       "county_name                   0\n",
       "county_fips                   0\n",
       "fine_grained_location       202\n",
       "police_department             0\n",
       "driver_gender                 0\n",
       "driver_age_raw              767\n",
       "driver_age                    0\n",
       "driver_race_raw               0\n",
       "driver_race                   0\n",
       "violation_raw                 0\n",
       "violation                     0\n",
       "search_conducted              0\n",
       "search_type_raw               0\n",
       "search_type              270902\n",
       "contraband_found              0\n",
       "stop_outcome                  0\n",
       "is_arrested                   0\n",
       "officer_id                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Location is needed to build an accurate model, so all missing data will be dropped\n",
    "data = data.dropna(subset = ['county_name'])\n",
    "\n",
    "# Driver's gender is also needed, so will drop records without gender\n",
    "data = data.dropna(subset = ['driver_gender'])\n",
    "\n",
    "# Driver's race is also needed, so will drop records without race\n",
    "data = data.dropna(subset = ['driver_race'])\n",
    "\n",
    "# Violation is also needed, so will drop records without violation\n",
    "data = data.dropna(subset = ['violation'])\n",
    "\n",
    "# Search Type Raw, Contraband Found, Stop Outcome and Officer ID only include 500 records for missing values, so we will drop these fields too\n",
    "data = data.dropna(subset = ['search_type_raw'])\n",
    "data = data.dropna(subset = ['contraband_found'])\n",
    "data = data.dropna(subset = ['stop_outcome'])\n",
    "data = data.dropna(subset = ['officer_id'])\n",
    "\n",
    "# Driver's age is important but to avoid dropping further data we will fill this in with average age\n",
    "data['driver_age']=data['driver_age'].astype(float) #convert data from strings to floats\n",
    "mean = data['driver_age'].mean()\n",
    "print(\"mean=\", mean)\n",
    "data['driver_age'].fillna(mean, inplace=True)\n",
    "\n",
    "pd.isnull(data).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(274201, 23)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns 'is_arrested' and 'stop_outcome' contain the same data in a different form. One of those columns needs to be deleted, otherwise, we would have data leakage. Choosing 'stop_outcome' would lead to a multiclass classification; therefore we will do classification on column 'is_arrested'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>is_arrested</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stop_outcome</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Arrest for Violation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Citation</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Verbal Warning</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Warrant Arrest</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Written Warning</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "is_arrested           False  True \n",
       "stop_outcome                      \n",
       "Arrest for Violation    0.0    1.0\n",
       "Citation                1.0    0.0\n",
       "Verbal Warning          1.0    0.0\n",
       "Warrant Arrest          0.0    1.0\n",
       "Written Warning         1.0    0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(data.stop_outcome, data.is_arrested, normalize='index')\n",
    "#columns is_arrested and stop_outcome have the same data, one of these needs to be deleted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the correlation table, we see that the column that has the greatest correlation with the class label is column 'search_conducted'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county_fips</th>\n",
       "      <th>driver_age_raw</th>\n",
       "      <th>driver_age</th>\n",
       "      <th>search_conducted</th>\n",
       "      <th>is_arrested</th>\n",
       "      <th>officer_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>county_fips</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.023329</td>\n",
       "      <td>0.023391</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>-0.000168</td>\n",
       "      <td>-0.020262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>driver_age_raw</td>\n",
       "      <td>0.023329</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999646</td>\n",
       "      <td>-0.075187</td>\n",
       "      <td>-0.043471</td>\n",
       "      <td>-0.006270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>driver_age</td>\n",
       "      <td>0.023391</td>\n",
       "      <td>0.999646</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.074852</td>\n",
       "      <td>-0.043433</td>\n",
       "      <td>-0.006253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>search_conducted</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>-0.075187</td>\n",
       "      <td>-0.074852</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.269260</td>\n",
       "      <td>0.010091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>is_arrested</td>\n",
       "      <td>-0.000168</td>\n",
       "      <td>-0.043471</td>\n",
       "      <td>-0.043433</td>\n",
       "      <td>0.269260</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>officer_id</td>\n",
       "      <td>-0.020262</td>\n",
       "      <td>-0.006270</td>\n",
       "      <td>-0.006253</td>\n",
       "      <td>0.010091</td>\n",
       "      <td>0.013594</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  county_fips  driver_age_raw  driver_age  search_conducted  \\\n",
       "county_fips          1.000000        0.023329    0.023391          0.000467   \n",
       "driver_age_raw       0.023329        1.000000    0.999646         -0.075187   \n",
       "driver_age           0.023391        0.999646    1.000000         -0.074852   \n",
       "search_conducted     0.000467       -0.075187   -0.074852          1.000000   \n",
       "is_arrested         -0.000168       -0.043471   -0.043433          0.269260   \n",
       "officer_id          -0.020262       -0.006270   -0.006253          0.010091   \n",
       "\n",
       "                  is_arrested  officer_id  \n",
       "county_fips         -0.000168   -0.020262  \n",
       "driver_age_raw      -0.043471   -0.006270  \n",
       "driver_age          -0.043433   -0.006253  \n",
       "search_conducted     0.269260    0.010091  \n",
       "is_arrested          1.000000    0.013594  \n",
       "officer_id           0.013594    1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a closer look at the relationship between these two columns ('is_arrested' and 'search_conducted'). From the cross table we see that only 0.08% drivers for whom search was not conducted were arrested. On the other side, 27% of the drivers that were arrested were searched as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>is_arrested</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search_conducted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>False</td>\n",
       "      <td>0.991237</td>\n",
       "      <td>0.008763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>True</td>\n",
       "      <td>0.722340</td>\n",
       "      <td>0.277660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "is_arrested          False     True \n",
       "search_conducted                    \n",
       "False             0.991237  0.008763\n",
       "True              0.722340  0.277660"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(data.search_conducted, data.is_arrested, normalize='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same table, we can see the relationship between the driver's race and whether they were arrested or not. It shows that a greater percentage of Black and Hispanic drivers were arrested compared to White and Asian drivers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>is_arrested</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>driver_race</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Asian</td>\n",
       "      <td>0.993638</td>\n",
       "      <td>0.006362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Black</td>\n",
       "      <td>0.978354</td>\n",
       "      <td>0.021646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hispanic</td>\n",
       "      <td>0.982463</td>\n",
       "      <td>0.017537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Other</td>\n",
       "      <td>0.973585</td>\n",
       "      <td>0.026415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>White</td>\n",
       "      <td>0.988202</td>\n",
       "      <td>0.011798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "is_arrested     False     True \n",
       "driver_race                    \n",
       "Asian        0.993638  0.006362\n",
       "Black        0.978354  0.021646\n",
       "Hispanic     0.982463  0.017537\n",
       "Other        0.973585  0.026415\n",
       "White        0.988202  0.011798"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(data.driver_race, data.is_arrested, normalize = 'index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature 'id' would not make sense to use as a predictive feature. As the whole dataset is made in Vermont, the column 'state' is the same in all rows. Therefore we can drop these two columns. Some columns are doubled, meaning that there is raw data that the officer wrote, and the data with values that are unified in the state. That means that the actual data (the one that is not raw) is more consistent, but the raw data has more variability. Looking at the values of these columns, we can see if raw data is more useful than the actual data, and choose which one to use for a certain feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_time</th>\n",
       "      <th>location_raw</th>\n",
       "      <th>county_fips</th>\n",
       "      <th>police_department</th>\n",
       "      <th>driver_gender</th>\n",
       "      <th>driver_age</th>\n",
       "      <th>driver_race_raw</th>\n",
       "      <th>violation</th>\n",
       "      <th>search_conducted</th>\n",
       "      <th>search_type_raw</th>\n",
       "      <th>contraband_found</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:10</td>\n",
       "      <td>East Montpelier</td>\n",
       "      <td>50023.0</td>\n",
       "      <td>MIDDLESEX VSP</td>\n",
       "      <td>M</td>\n",
       "      <td>22.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Moving violation</td>\n",
       "      <td>False</td>\n",
       "      <td>No Search Conducted</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>00:11</td>\n",
       "      <td>Whiting</td>\n",
       "      <td>50001.0</td>\n",
       "      <td>NEW HAVEN VSP</td>\n",
       "      <td>F</td>\n",
       "      <td>18.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Moving violation</td>\n",
       "      <td>False</td>\n",
       "      <td>No Search Conducted</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>00:35</td>\n",
       "      <td>Hardwick</td>\n",
       "      <td>50005.0</td>\n",
       "      <td>ROYALTON VSP</td>\n",
       "      <td>M</td>\n",
       "      <td>18.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Moving violation</td>\n",
       "      <td>False</td>\n",
       "      <td>No Search Conducted</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>00:44</td>\n",
       "      <td>Hardwick</td>\n",
       "      <td>50005.0</td>\n",
       "      <td>ROYALTON VSP</td>\n",
       "      <td>F</td>\n",
       "      <td>20.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Equipment</td>\n",
       "      <td>False</td>\n",
       "      <td>No Search Conducted</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>01:10</td>\n",
       "      <td>Rochester</td>\n",
       "      <td>50027.0</td>\n",
       "      <td>ROCKINGHAM VSP</td>\n",
       "      <td>M</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Black</td>\n",
       "      <td>Moving violation</td>\n",
       "      <td>False</td>\n",
       "      <td>No Search Conducted</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stop_time     location_raw  county_fips police_department driver_gender  \\\n",
       "0     00:10  East Montpelier      50023.0     MIDDLESEX VSP             M   \n",
       "3     00:11          Whiting      50001.0     NEW HAVEN VSP             F   \n",
       "4     00:35         Hardwick      50005.0      ROYALTON VSP             M   \n",
       "5     00:44         Hardwick      50005.0      ROYALTON VSP             F   \n",
       "8     01:10        Rochester      50027.0    ROCKINGHAM VSP             M   \n",
       "\n",
       "   driver_age driver_race_raw         violation  search_conducted  \\\n",
       "0        22.0           White  Moving violation             False   \n",
       "3        18.0           White  Moving violation             False   \n",
       "4        18.0           White  Moving violation             False   \n",
       "5        20.0           White         Equipment             False   \n",
       "8        24.0           Black  Moving violation             False   \n",
       "\n",
       "       search_type_raw contraband_found  \n",
       "0  No Search Conducted            False  \n",
       "3  No Search Conducted            False  \n",
       "4  No Search Conducted            False  \n",
       "5  No Search Conducted            False  \n",
       "8  No Search Conducted            False  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_X = data.drop(['id','state','fine_grained_location','stop_date','driver_age_raw','stop_outcome','violation_raw','search_type','county_name','driver_race','officer_id', 'is_arrested'], axis = 1)\n",
    "features_X.corr()\n",
    "\n",
    "classLabel_Y = data['is_arrested']\n",
    "features_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are features that are categorical. We need to convert them to numbers to be able to make models on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_time</th>\n",
       "      <th>location_raw</th>\n",
       "      <th>county_fips</th>\n",
       "      <th>police_department</th>\n",
       "      <th>driver_gender</th>\n",
       "      <th>driver_age</th>\n",
       "      <th>driver_race_raw</th>\n",
       "      <th>violation</th>\n",
       "      <th>search_conducted</th>\n",
       "      <th>search_type_raw</th>\n",
       "      <th>contraband_found</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>88</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>324</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>70</td>\n",
       "      <td>234</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stop_time  location_raw  county_fips  police_department  driver_gender  \\\n",
       "0         10            88           11                  3              1   \n",
       "3         11           324            0                  4              0   \n",
       "4         35           128            2                  6              1   \n",
       "5         44           128            2                  6              0   \n",
       "8         70           234           13                  5              1   \n",
       "\n",
       "   driver_age  driver_race_raw  violation  search_conducted  search_type_raw  \\\n",
       "0        22.0                4          2             False                3   \n",
       "3        18.0                4          2             False                3   \n",
       "4        18.0                4          2             False                3   \n",
       "5        20.0                4          1             False                3   \n",
       "8        24.0                1          2             False                3   \n",
       "\n",
       "   contraband_found  \n",
       "0                 0  \n",
       "3                 0  \n",
       "4                 0  \n",
       "5                 0  \n",
       "8                 0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "\n",
    "# Converting all labels to numbers\n",
    "features_X['location_raw']= label_encoder.fit_transform(features_X['location_raw']) \n",
    "features_X['county_fips']= label_encoder.fit_transform(features_X['county_fips'])\n",
    "features_X['police_department']= label_encoder.fit_transform(features_X['police_department'])\n",
    "features_X['driver_gender']= label_encoder.fit_transform(features_X['driver_gender'])\n",
    "features_X['driver_race_raw']= label_encoder.fit_transform(features_X['driver_race_raw'])\n",
    "features_X['violation']= label_encoder.fit_transform(features_X['violation'])\n",
    "features_X['search_type_raw']= label_encoder.fit_transform(features_X['search_type_raw'])\n",
    "features_X['contraband_found']= label_encoder.fit_transform(features_X['contraband_found'])\n",
    "#features_X['stop_outcome']= label_encoder.fit_transform(features_X['stop_outcome'])\n",
    "features_X['stop_time']= label_encoder.fit_transform(features_X['stop_time'])\n",
    "\n",
    "#features_X['is_arrested']= label_encoder.fit_transform(features_X['is_arrested'])\n",
    "\n",
    "features_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the dataset is imbalanced, we need to balance it. We will oversample the minority class with using Smote, and then undersample the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({False: 270911, True: 3290})\n",
      "Counter({False: 4514, True: 4063})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8577, 11)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imblearn\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import sklearn as sk\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "#number of true/false in class label before balancing data\n",
    "counter = Counter(classLabel_Y)\n",
    "print(counter)\n",
    "#the data needs to be balanced\n",
    "#oversampeling the minority class with smote\n",
    "\n",
    "oversample = SMOTE(sampling_strategy=0.015)\n",
    "data_X, data_Y = oversample.fit_resample(features_X, classLabel_Y)\n",
    "#undersampeling the majority class\n",
    "under = RandomUnderSampler(sampling_strategy=0.9)\n",
    "data_X, data_Y = under.fit_resample(data_X, data_Y)\n",
    "#number of true/false in class label afrer balancing data\n",
    "counter = Counter(data_Y)\n",
    "print(counter)\n",
    "\n",
    "data_X = pd.DataFrame(data_X)\n",
    "data_Y = pd.DataFrame(data_Y)\n",
    "\n",
    "\n",
    "data_X.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes\n",
    "We will use Naive Bayes to make a model, because the features are independent from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 66.6195844808326\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.61      0.99      0.76      4514\n",
      "        True       0.96      0.31      0.47      4063\n",
      "\n",
      "    accuracy                           0.67      8577\n",
      "   macro avg       0.79      0.65      0.61      8577\n",
      "weighted avg       0.78      0.67      0.62      8577\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "#classifing with naive bayes\n",
    "clf = GaussianNB()\n",
    "scores = cross_val_score(clf, data_X, data_Y, cv=10) \n",
    "predicts = cross_val_predict(clf, data_X, data_Y, cv=10) \n",
    "\n",
    "print(\"Accuracy:\", scores.mean()*100)\n",
    "print(classification_report(data_Y, predicts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K Nearest Neighbors\n",
    "For k nearest neighbors classifier we need to use scaler and PCA dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 8, 'pca__n_components': 9}\n",
      "Accuracy: 72.81120568601816\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.71      0.82      0.76      4514\n",
      "        True       0.76      0.63      0.69      4063\n",
      "\n",
      "    accuracy                           0.73      8577\n",
      "   macro avg       0.73      0.72      0.72      8577\n",
      "weighted avg       0.73      0.73      0.73      8577\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "scaler = sk.preprocessing.MinMaxScaler()\n",
    "pca = PCA()\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "pipe = Pipeline(steps=[('scaler', scaler), ('pca', pca), ('knn', knn)])\n",
    "\n",
    "param_grid = {\n",
    "    'pca__n_components': list(range(1, 11)),\n",
    "    'knn__n_neighbors': list(range(1, 10)),  \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV( pipe, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(data_X, data_Y)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "nested_score = cross_val_score(grid_search, data_X, data_Y, cv=5)\n",
    "print(\"Accuracy:\", nested_score.mean()*100)\n",
    "\n",
    "\n",
    "predicts = cross_val_predict(grid_search, data_X, data_Y, cv=5) \n",
    "print(classification_report(data_Y, predicts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MLP__activation': 'relu', 'MLP__hidden_layer_sizes': (60,)}\n",
      "Accuracy: 74.33865139456547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.72      0.84      0.78      4514\n",
      "        True       0.78      0.64      0.71      4063\n",
      "\n",
      "    accuracy                           0.75      8577\n",
      "   macro avg       0.75      0.74      0.74      8577\n",
      "weighted avg       0.75      0.75      0.74      8577\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "scaler = sk.preprocessing.MinMaxScaler()\n",
    "clf = MLPClassifier()\n",
    "\n",
    "pipe =  Pipeline(steps=[('scaler', scaler), ('MLP', clf)])\n",
    "\n",
    "param_grid = {'MLP__hidden_layer_sizes': [(10,), (20,), (30,), (40,), (50,), (60,),(70,)],\n",
    "             'MLP__activation' : ['identity', 'logistic', 'tanh', 'relu']}\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(data_X, data_Y)\n",
    "print(grid_search.best_params_)\n",
    "nested_score = cross_val_score(grid_search, data_X, data_Y, cv=5)\n",
    "\n",
    "print(\"Accuracy:\", nested_score.mean()*100)\n",
    "\n",
    "predicts = cross_val_predict(grid_search, data_X, data_Y, cv=5) \n",
    "print(classification_report(data_Y, predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machines \n",
    "For support vector machines we need to use scaler and PCA dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SVM__kernel': 'rbf', 'pca__n_components': 7}\n",
      "Accuracy: 69.21996640592596\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.64      0.97      0.77      4514\n",
      "        True       0.91      0.39      0.54      4063\n",
      "\n",
      "    accuracy                           0.69      8577\n",
      "   macro avg       0.78      0.68      0.66      8577\n",
      "weighted avg       0.77      0.69      0.66      8577\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "\n",
    "scaler = sk.preprocessing.MinMaxScaler()\n",
    "clf = SVC()\n",
    "pca = PCA()\n",
    "pipe =  Pipeline(steps=[('scaler', scaler), ('pca',pca), ('SVM', clf)])\n",
    "\n",
    "param_grid = {'SVM__kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "             'pca__n_components': list(range(1, 11))}\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(data_X, data_Y)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "nested_score = cross_val_score(grid_search, data_X, data_Y, cv=5)\n",
    "print(\"Accuracy:\", nested_score.mean()*100)\n",
    "predicts = cross_val_predict(grid_search, data_X, data_Y, cv=5) \n",
    "print(classification_report(data_Y, predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 110}\n",
      "Accuracy: 74.08177863460887\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.71      0.86      0.78      4514\n",
      "        True       0.80      0.61      0.69      4063\n",
      "\n",
      "    accuracy                           0.74      8577\n",
      "   macro avg       0.75      0.73      0.73      8577\n",
      "weighted avg       0.75      0.74      0.74      8577\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "clf = AdaBoostClassifier()\n",
    "\n",
    "par = {\"n_estimators\": range(10,200,20) }\n",
    "\n",
    "grid_search = GridSearchCV(clf, par, cv=5, scoring='accuracy')\n",
    "grid_search.fit(data_X, data_Y)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "nested_score = cross_val_score(grid_search, data_X, data_Y, cv=5)\n",
    "\n",
    "print(\"Accuracy:\", nested_score.mean()*100)\n",
    "predicts = cross_val_predict(grid_search, data_X, data_Y, cv=5) \n",
    "print(classification_report(data_Y, predicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 44, 'max_features': 'sqrt', 'min_samples_leaf': 9}\n",
      "Accuracy: 75.03829193770375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.72      0.86      0.78      4514\n",
      "        True       0.80      0.62      0.70      4063\n",
      "\n",
      "    accuracy                           0.75      8577\n",
      "   macro avg       0.76      0.74      0.74      8577\n",
      "weighted avg       0.76      0.75      0.74      8577\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "par = {\"max_depth\": range(30,45) , \n",
    "      \"min_samples_leaf\": [9,12,15,18],\n",
    "       \"max_features\" : ['sqrt', 'log2']}\n",
    "\n",
    "grid_search = GridSearchCV(clf, par, cv=5, scoring='accuracy')\n",
    "grid_search.fit(data_X, data_Y)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "nested_score = cross_val_score(grid_search, data_X, data_Y, cv=5)\n",
    "\n",
    "print(\"Accuracy:\", nested_score.mean()*100)\n",
    "predicts = cross_val_predict(grid_search, data_X, data_Y, cv=5) \n",
    "print(classification_report(data_Y, predicts))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
